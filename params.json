{"name":"Practical-machine-learning-course-project","tagline":"Practical Machine Learning Course Project","body":"# Practical Machine Learning Course Project\r\nFredrik Emilsson  \r\nMonday, March 16, 2015  \r\n\r\n\r\n\r\n# Introduction\r\nThe goal of the project was to predict the manner in which they did the exercise. This is the \"classe\" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did.\r\n\r\n# The data\r\nThe two data frames are training and testing. Training are used to do the estimation. \r\nTraining data frame contains 19622 observations on 160 variables and testing data frame contains 20 observations on 160 variables. Only the training data will be used. The testing data is only used for the submission.\r\n\r\n# Loading and preprocessing tha data\r\nLoad the data:\r\n\r\n```r\r\ntesting <- read.table(\"./pml-testing.csv\", sep = \",\", header = TRUE)\r\ntraining <- read.table(\"./pml-training.csv\", sep = \",\", header = TRUE)\r\n```\r\n\r\nExcept loading the data also a number of other steps has to be done before we can create a correct model. The following steps was done:\r\n\r\n- Remove columns that are not related to the data (1-7).\r\n\r\n- Remove columns that includes NA values.\r\n\r\n- Remove attributes that deals with skewness or kurtosis.\r\n\r\n- Remove near zero variance predictors.\r\n\r\n\r\n\r\n```r\r\n# Remove columns that are not related to the data (1-7)\r\ntesting <- testing[,-c(1:7)]                      \r\ntraining <- training[,-c(1:7)]            \r\n\r\n# Remove columns that includes NA values\r\nna_columns <- colSums(is.na(training))\r\ntraining = training[,na_columns == 0]\r\ntesting = testing[,na_columns == 0]\r\n\r\n# Remove attributes that deals with skewness or kurtosis\r\ntraining <- training[,!(names(training) %in% names(training)[grep(\"^skew\",names(training))])]\r\ntraining <- training[,!(names(training) %in% names(training)[grep(\"^kurt\",names(training))])]\r\ntesting <- testing[,!(names(testing) %in% names(testing)[grep(\"^skew\",names(testing))])]\r\ntesting <- testing[,!(names(testing) %in% names(testing)[grep(\"^kurt\",names(testing))])]\r\n\r\n# Remove near zero variance predictors\r\nnzv <- nearZeroVar(training,saveMetrics=TRUE)\r\ntraining <- training[,nzv$nzv==FALSE]\r\ntesting <- testing[,nzv$nzv==FALSE]\r\n\r\n# Final included variables\r\nnames(training)\r\n```\r\n\r\n```\r\n##  [1] \"roll_belt\"            \"pitch_belt\"           \"yaw_belt\"            \r\n##  [4] \"total_accel_belt\"     \"gyros_belt_x\"         \"gyros_belt_y\"        \r\n##  [7] \"gyros_belt_z\"         \"accel_belt_x\"         \"accel_belt_y\"        \r\n## [10] \"accel_belt_z\"         \"magnet_belt_x\"        \"magnet_belt_y\"       \r\n## [13] \"magnet_belt_z\"        \"roll_arm\"             \"pitch_arm\"           \r\n## [16] \"yaw_arm\"              \"total_accel_arm\"      \"gyros_arm_x\"         \r\n## [19] \"gyros_arm_y\"          \"gyros_arm_z\"          \"accel_arm_x\"         \r\n## [22] \"accel_arm_y\"          \"accel_arm_z\"          \"magnet_arm_x\"        \r\n## [25] \"magnet_arm_y\"         \"magnet_arm_z\"         \"roll_dumbbell\"       \r\n## [28] \"pitch_dumbbell\"       \"yaw_dumbbell\"         \"total_accel_dumbbell\"\r\n## [31] \"gyros_dumbbell_x\"     \"gyros_dumbbell_y\"     \"gyros_dumbbell_z\"    \r\n## [34] \"accel_dumbbell_x\"     \"accel_dumbbell_y\"     \"accel_dumbbell_z\"    \r\n## [37] \"magnet_dumbbell_x\"    \"magnet_dumbbell_y\"    \"magnet_dumbbell_z\"   \r\n## [40] \"roll_forearm\"         \"pitch_forearm\"        \"yaw_forearm\"         \r\n## [43] \"total_accel_forearm\"  \"gyros_forearm_x\"      \"gyros_forearm_y\"     \r\n## [46] \"gyros_forearm_z\"      \"accel_forearm_x\"      \"accel_forearm_y\"     \r\n## [49] \"accel_forearm_z\"      \"magnet_forearm_x\"     \"magnet_forearm_y\"    \r\n## [52] \"magnet_forearm_z\"     \"classe\"\r\n```\r\n\r\n# Create the model\r\nNow it is time to create a model.\r\n\r\nFirst split up the test data in a training set (60%) and a test set (40%):\r\n\r\n```r\r\nset.seed(125)\r\ninTrain = createDataPartition(training$classe, p = 0.6)[[1]]\r\ntrainData = training[ inTrain,]\r\ntestData = training[-inTrain,]\r\n```\r\nNow it is time to fit the model by using Caret. I decided to use random forest. It seems to be a good model for this type of data. I decided to set the cross validation to 5 k-folds (as we will see later I tested a number of k-folds but find 5 as a good trade-off value).\r\n\r\n\r\n```r\r\ntc <- trainControl(method=\"cv\", number=5)\r\nmodFit <- train(classe ~ .,data=trainData,method=\"rf\",trControl=tc)\r\n```\r\n\r\n```\r\n## Loading required package: randomForest\r\n## randomForest 4.6-10\r\n## Type rfNews() to see new features/changes/bug fixes.\r\n```\r\n\r\n```r\r\nmodFit\r\n```\r\n\r\n```\r\n## Random Forest \r\n## \r\n## 11776 samples\r\n##    52 predictor\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (5 fold) \r\n## \r\n## Summary of sample sizes: 9421, 9421, 9421, 9420, 9421 \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   \r\n##    2    0.9906593  0.9881826  0.002224373  0.002816493\r\n##   27    0.9890458  0.9861414  0.002605490  0.003298396\r\n##   52    0.9797043  0.9743263  0.003009641  0.003804880\r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 2.\r\n```\r\n\r\n# Predict using the model\r\nNow we want to validate it by use prediction on the test data to estimate the out of sample error.\r\n\r\n```r\r\npred <- predict(modFit,newdata=testData)\r\ntable(pred,testData$classe)\r\n```\r\n\r\n```\r\n##     \r\n## pred    A    B    C    D    E\r\n##    A 2232   21    0    0    0\r\n##    B    0 1485   18    0    0\r\n##    C    0   12 1349   47    0\r\n##    D    0    0    1 1239    4\r\n##    E    0    0    0    0 1438\r\n```\r\n\r\n```r\r\nmean(pred!=testData$classe)\r\n```\r\n\r\n```\r\n## [1] 0.01312771\r\n```\r\nThe out of sample error are 0.013, which I think is a good value. \r\n\r\nI did a similar run for 2,5 and 10 and the out of sample errors are:\r\n\r\n- 2: 0.0144\r\n\r\n- 5: 0.0130\r\n\r\n- 10: 0.0119\r\n\r\n# Final model\r\nThe final model is determined and the prediction is performed on the testing data. The same prediction will also be used to execute the 20 different test cases.\r\n\r\n```r\r\npred <- predict(modFit,newdata=testing)\r\npred\r\n```\r\n\r\n```\r\n##  [1] B A B A A E D B A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n```\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}